{"cells":[{"cell_type":"markdown","metadata":{"id":"PW1uSiRkmU9m"},"source":["# Connecting the notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53121,"status":"ok","timestamp":1660117456558,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"SJV9xNaykF_C","outputId":"d35c7b45-166b-45e3-f1f2-ab51e608f478"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"hQT-lmsBceCc"},"source":["# importation"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1660117456560,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"J9opTsmjcVeE"},"outputs":[],"source":["import itertools\n","import os\n","import random\n","import six\n","import numpy as np\n","import cv2\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1660117456563,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"csoFa5yNdsOy"},"outputs":[],"source":["try:\n","    from collections.abc import Sequence\n","except ImportError:\n","    from collections import Sequence\n","try:\n","    from tqdm import tqdm\n","except ImportError:\n","    print(\"tqdm not found, disabling progress bars\")\n","\n","def tqdm(iter):\n","    return iter"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3396,"status":"ok","timestamp":1660117459946,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"spFmfih6eJQJ"},"outputs":[],"source":["#fixing the seed\n","import tensorflow as tf\n","seed_value=1254\n","#os.environ['PYTHONHASHSEEN']='0'\n","os.environ['PYTHONHASHSEEN']='1254'\n","np.random.seed(seed_value)\n","tf.random.set_seed(seed_value)\n","#DATA_LOADER_SEED = 1254\n","random.seed(seed_value)\n","from tensorflow import random as tr\n","tr.set_seed(1234)"]},{"cell_type":"markdown","metadata":{"id":"41knRT76mxkq"},"source":["## Taking care of reproducibility "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660117459947,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"KE29ZEqwTNVM"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import random as tr\n","seed_value=1254\n","os.environ['PYTHONHASHSEEN']='0'\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","tr.set_seed(1234)\n","#confihgure a new global tensorflow session \n"]},{"cell_type":"markdown","metadata":{"id":"TQYK053KcmNp"},"source":["# Necessary functions "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660117459948,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"rpRiZZTneW5P"},"outputs":[],"source":["IMAGE_ORDERING_CHANNELS_LAST = \"channels_last\"\n","IMAGE_ORDERING_CHANNELS_FIRST = \"channels_first\"\n","\n","# Default IMAGE_ORDERING = channels_last\n","IMAGE_ORDERING = IMAGE_ORDERING_CHANNELS_LAST"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":621,"status":"ok","timestamp":1660117460560,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"CICQvEBVeq7f"},"outputs":[],"source":["#augmentation \n","\n","import numpy as np\n","\n","try:\n","    import imgaug as ia\n","    from imgaug import augmenters as iaa\n","except ImportError:\n","    print(\"Error in loading augmentation, can't import imgaug.\"\n","          \"Please make sure it is installed.\")\n","\n","IMAGE_AUGMENTATION_SEQUENCE = None\n","IMAGE_AUGMENTATION_NUM_TRIES = 10\n","\n","loaded_augmentation_name = \"\"\n","\n","def _load_augmentation_aug_geometric():\n","    return iaa.OneOf([\n","        iaa.Sequential([iaa.Fliplr(0.5), iaa.Flipud(0.2)]),\n","        iaa.CropAndPad(percent=(-0.05, 0.1),\n","                       pad_mode='constant',\n","                       pad_cval=(0, 255)),\n","        iaa.Crop(percent=(0.0, 0.1)),\n","        iaa.Crop(percent=(0.3, 0.5)),\n","        iaa.Crop(percent=(0.3, 0.5)),\n","        iaa.Crop(percent=(0.3, 0.5)),\n","        iaa.Sequential([\n","            iaa.Affine(\n","                    # scale images to 80-120% of their size,\n","                    # individually per axis\n","                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n","                    # translate by -20 to +20 percent (per axis)\n","                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","                    rotate=(-45, 45),  # rotate by -45 to +45 degrees\n","                    shear=(-16, 16),  # shear by -16 to +16 degrees\n","                    # use nearest neighbour or bilinear interpolation (fast)\n","                    order=[0, 1],\n","                    # if mode is constant, use a cval between 0 and 255\n","                    mode='constant',\n","                    cval=(0, 255),\n","                    # use any of scikit-image's warping modes\n","                    # (see 2nd image from the top for examples)\n","            ),\n","            iaa.Sometimes(0.3, iaa.Crop(percent=(0.3, 0.5)))])\n","    ])\n","\n","\n","def _load_augmentation_aug_non_geometric():\n","    return iaa.Sequential([\n","        iaa.Sometimes(0.3, iaa.Multiply((0.5, 1.5), per_channel=0.5)),\n","        iaa.Sometimes(0.2, iaa.JpegCompression(compression=(70, 99))),\n","        iaa.Sometimes(0.2, iaa.GaussianBlur(sigma=(0, 3.0))),\n","        iaa.Sometimes(0.2, iaa.MotionBlur(k=15, angle=[-45, 45])),\n","        iaa.Sometimes(0.2, iaa.MultiplyHue((0.5, 1.5))),\n","        iaa.Sometimes(0.2, iaa.MultiplySaturation((0.5, 1.5))),\n","        iaa.Sometimes(0.34, iaa.MultiplyHueAndSaturation((0.5, 1.5),\n","                                                         per_channel=True)),\n","        iaa.Sometimes(0.34, iaa.Grayscale(alpha=(0.0, 1.0))),\n","        iaa.Sometimes(0.2, iaa.ChangeColorTemperature((1100, 10000))),\n","        iaa.Sometimes(0.1, iaa.GammaContrast((0.5, 2.0))),\n","        iaa.Sometimes(0.2, iaa.SigmoidContrast(gain=(3, 10),\n","                                               cutoff=(0.4, 0.6))),\n","        iaa.Sometimes(0.1, iaa.CLAHE()),\n","        iaa.Sometimes(0.1, iaa.HistogramEqualization()),\n","        iaa.Sometimes(0.2, iaa.LinearContrast((0.5, 2.0), per_channel=0.5)),\n","        iaa.Sometimes(0.1, iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)))\n","    ])\n","\n","\n","def _load_augmentation_aug_all2():\n","    return iaa.Sequential([\n","        iaa.Sometimes(0.65, _load_augmentation_aug_non_geometric()),\n","        iaa.Sometimes(0.65, _load_augmentation_aug_geometric())\n","    ])\n","\n","\n","def _load_augmentation_aug_all():\n","    \"\"\" Load image augmentation model \"\"\"\n","\n","    def sometimes(aug):\n","        return iaa.Sometimes(0.5, aug)\n","\n","    return iaa.Sequential(\n","        [\n","            # apply the following augmenters to most images\n","            iaa.Fliplr(0.5),  # horizontally flip 50% of all images\n","            iaa.Flipud(0.2),  # vertically flip 20% of all images\n","            # crop images by -5% to 10% of their height/width\n","            sometimes(iaa.CropAndPad(\n","                percent=(-0.05, 0.1),\n","                pad_mode='constant',\n","                pad_cval=(0, 255)\n","            )),\n","            sometimes(iaa.Affine(\n","                # scale images to 80-120% of their size, individually per axis\n","                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n","                # translate by -20 to +20 percent (per axis)\n","                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","                rotate=(-45, 45),  # rotate by -45 to +45 degrees\n","                shear=(-16, 16),  # shear by -16 to +16 degrees\n","                # use nearest neighbour or bilinear interpolation (fast)\n","                order=[0, 1],\n","                # if mode is constant, use a cval between 0 and 255\n","                cval=(0, 255),\n","                # use any of scikit-image's warping modes\n","                # (see 2nd image from the top for examples)\n","                mode='constant'\n","            )),\n","            # execute 0 to 5 of the following (less important) augmenters per\n","            # image don't execute all of them, as that would often be way too\n","            # strong\n","            iaa.SomeOf((0, 5),\n","                       [\n","                # convert images into their superpixel representation\n","                sometimes(iaa.Superpixels(\n","                    p_replace=(0, 1.0), n_segments=(20, 200))),\n","                iaa.OneOf([\n","                    # blur images with a sigma between 0 and 3.0\n","                    iaa.GaussianBlur((0, 3.0)),\n","                    # blur image using local means with kernel sizes\n","                    # between 2 and 7\n","                    iaa.AverageBlur(k=(2, 7)),\n","                    # blur image using local medians with kernel sizes\n","                    # between 2 and 7\n","                    iaa.MedianBlur(k=(3, 11)),\n","                ]),\n","                iaa.Sharpen(alpha=(0, 1.0), lightness=(\n","                            0.75, 1.5)),  # sharpen images\n","                iaa.Emboss(alpha=(0, 1.0), strength=(\n","                    0, 2.0)),  # emboss images\n","                # search either for all edges or for directed edges,\n","                # blend the result with the original image using a blobby mask\n","                iaa.BlendAlphaSimplexNoise(iaa.OneOf([\n","                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n","                    iaa.DirectedEdgeDetect(\n","                        alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n","                ])),\n","                # add gaussian noise to images\n","                iaa.AdditiveGaussianNoise(loc=0, scale=(\n","                    0.0, 0.05*255), per_channel=0.5),\n","                iaa.OneOf([\n","                    # randomly remove up to 10% of the pixels\n","                    iaa.Dropout((0.01, 0.1), per_channel=0.5),\n","                    iaa.CoarseDropout((0.03, 0.15), size_percent=(\n","                        0.02, 0.05), per_channel=0.2),\n","                ]),\n","                # invert color channels\n","                iaa.Invert(0.05, per_channel=True),\n","                # change brightness of images (by -10 to 10 of original value)\n","                iaa.Add((-10, 10), per_channel=0.5),\n","                # change hue and saturation\n","                iaa.AddToHueAndSaturation((-20, 20)),\n","                # either change the brightness of the whole image (sometimes\n","                # per channel) or change the brightness of subareas\n","                iaa.OneOf([\n","                    iaa.Multiply(\n","                                (0.5, 1.5), per_channel=0.5),\n","                    iaa.BlendAlphaFrequencyNoise(\n","                        exponent=(-4, 0),\n","                        foreground=iaa.Multiply(\n","                            (0.5, 1.5), per_channel=True),\n","                        background=iaa.contrast.LinearContrast(\n","                            (0.5, 2.0))\n","                    )\n","                ]),\n","                # improve or worsen the contrast\n","                iaa.contrast.LinearContrast((0.5, 2.0), per_channel=0.5),\n","                iaa.Grayscale(alpha=(0.0, 1.0)),\n","                # move pixels locally around (with random strengths)\n","                sometimes(iaa.ElasticTransformation(\n","                    alpha=(0.5, 3.5), sigma=0.25)),\n","                # sometimes move parts of the image around\n","                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n","                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n","            ],\n","                random_order=True\n","            )\n","        ],\n","        random_order=True\n","    )\n","\n","\n","augmentation_functions = {\n","    \"aug_all\": _load_augmentation_aug_all,\n","    \"aug_all2\": _load_augmentation_aug_all2,\n","    \"aug_geometric\": _load_augmentation_aug_geometric,\n","    \"aug_non_geometric\": _load_augmentation_aug_non_geometric\n","}\n","\n","\n","def _load_augmentation(augmentation_name=\"aug_all\"):\n","\n","    global IMAGE_AUGMENTATION_SEQUENCE\n","\n","    if augmentation_name not in augmentation_functions:\n","        raise ValueError(\"Augmentation name not supported\")\n","\n","    IMAGE_AUGMENTATION_SEQUENCE = augmentation_functions[augmentation_name]()\n","\n","\n","def _augment_seg(img, seg, augmentation_name=\"aug_all\", other_imgs=None):\n","\n","    global loaded_augmentation_name\n","\n","    if (not IMAGE_AUGMENTATION_SEQUENCE) or\\\n","       (augmentation_name != loaded_augmentation_name):\n","        _load_augmentation(augmentation_name)\n","        loaded_augmentation_name = augmentation_name\n","\n","    # Create a deterministic augmentation from the random one\n","    aug_det = IMAGE_AUGMENTATION_SEQUENCE.to_deterministic()\n","    # Augment the input image\n","    image_aug = aug_det.augment_image(img)\n","\n","    if other_imgs is not None:\n","        image_aug = [image_aug]\n","\n","        for other_img in other_imgs:\n","            image_aug.append(aug_det.augment_image(other_img))\n","\n","    segmap = ia.SegmentationMapsOnImage(\n","        seg, shape=img.shape)\n","    segmap_aug = aug_det.augment_segmentation_maps(segmap)\n","    segmap_aug = segmap_aug.get_arr()\n","\n","    return image_aug, segmap_aug\n","\n","\n","def _custom_augment_seg(img, seg, augmentation_function, other_imgs=None):\n","    augmentation_functions['custom_aug'] = augmentation_function\n","\n","    return _augment_seg(img, seg, \"custom_aug\", other_imgs=other_imgs)\n","\n","\n","def _try_n_times(fn, n, *args, **kargs):\n","    \"\"\" Try a function N times \"\"\"\n","    attempts = 0\n","    while attempts < n:\n","        try:\n","            return fn(*args, **kargs)\n","        except Exception:\n","            attempts += 1\n","\n","    return fn(*args, **kargs)\n","\n","\n","def augment_seg(img, seg, augmentation_name=\"aug_all\", other_imgs=None):\n","    return _try_n_times(_augment_seg, IMAGE_AUGMENTATION_NUM_TRIES,\n","                        img, seg, augmentation_name=augmentation_name,\n","                        other_imgs=other_imgs)\n","\n","\n","def custom_augment_seg(img, seg, augmentation_function, other_imgs=None):\n","    return _try_n_times(_custom_augment_seg, IMAGE_AUGMENTATION_NUM_TRIES,\n","                        img, seg, augmentation_function=augmentation_function,\n","                        other_imgs=other_imgs)\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":833,"status":"ok","timestamp":1660117461389,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"BRixn5CEd43y"},"outputs":[],"source":["class_colors = [(random.randint(0, 255), random.randint(\n","    0, 255), random.randint(0, 255)) for _ in range(5000)]\n","\n","ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n","ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n","\n","\n","class DataLoaderError(Exception):\n","    pass\n","\n","def get_image_list_from_path(images_path ):\n","    image_files = []\n","    for dir_entry in os.listdir(images_path):\n","            if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n","                    os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n","                file_name, file_extension = os.path.splitext(dir_entry)\n","                image_files.append(os.path.join(images_path, dir_entry))\n","    return image_files\n","\n","\n","def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False, other_inputs_paths=None):\n","    \"\"\" Find all the images from the images_path directory and\n","        the segmentation images from the segs_path directory\n","        while checking integrity of data \"\"\"\n","\n","    image_files = []\n","    segmentation_files = {}\n","\n","    for dir_entry in os.listdir(images_path):\n","        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n","                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n","            file_name, file_extension = os.path.splitext(dir_entry)\n","            image_files.append((file_name, file_extension,\n","                                os.path.join(images_path, dir_entry)))\n","\n","    if other_inputs_paths is not None:\n","        other_inputs_files = []\n","\n","        for i, other_inputs_path in enumerate(other_inputs_paths):\n","            temp = []\n","\n","            for y, dir_entry in enumerate(os.listdir(other_inputs_path)):\n","                if os.path.isfile(os.path.join(other_inputs_path, dir_entry)) and \\\n","                        os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n","                    file_name, file_extension = os.path.splitext(dir_entry)\n","\n","                    temp.append((file_name, file_extension,\n","                                 os.path.join(other_inputs_path, dir_entry)))\n","\n","            other_inputs_files.append(temp)\n","\n","    for dir_entry in os.listdir(segs_path):\n","        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n","           os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n","            file_name, file_extension = os.path.splitext(dir_entry)\n","            full_dir_entry = os.path.join(segs_path, dir_entry)\n","            if file_name in segmentation_files:\n","                raise DataLoaderError(\"Segmentation file with filename {0}\"\n","                                      \" already exists and is ambiguous to\"\n","                                      \" resolve with path {1}.\"\n","                                      \" Please remove or rename the latter.\"\n","                                      .format(file_name, full_dir_entry))\n","\n","            segmentation_files[file_name] = (file_extension, full_dir_entry)\n","\n","    return_value = []\n","    # Match the images and segmentations\n","    for image_file, _, image_full_path in image_files:\n","        if image_file in segmentation_files:\n","            if other_inputs_paths is not None:\n","                other_inputs = []\n","                for file_paths in other_inputs_files:\n","                    success = False\n","\n","                    for (other_file, _, other_full_path) in file_paths:\n","                        if image_file == other_file:\n","                            other_inputs.append(other_full_path)\n","                            success = True\n","                            break\n","\n","                    if not success:\n","                        raise ValueError(\"There was no matching other input to\", image_file, \"in directory\")\n","\n","                return_value.append((image_full_path,\n","                                     segmentation_files[image_file][1], other_inputs))\n","            else:\n","                return_value.append((image_full_path,\n","                                     segmentation_files[image_file][1]))\n","        elif ignore_non_matching:\n","            continue\n","        else:\n","            # Error out\n","            raise DataLoaderError(\"No corresponding segmentation \"\n","                                  \"found for image {0}\"\n","                                  .format(image_full_path))\n","\n","    return return_value\n","\n","\n","def get_image_array(image_input,\n","                    width, height,\n","                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n","    \"\"\" Load image array from input \"\"\"\n","\n","    if type(image_input) is np.ndarray:\n","        # It is already an array, use it as it is\n","        img = image_input\n","    elif isinstance(image_input, six.string_types):\n","        if not os.path.isfile(image_input):\n","            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n","                                  .format(image_input))\n","        img = cv2.imread(image_input, read_image_type)\n","    else:\n","        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n","                              .format(str(type(image_input))))\n","\n","    if imgNorm == \"sub_and_divide\":\n","        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n","    elif imgNorm == \"sub_mean\":\n","        img = cv2.resize(img, (width, height))\n","        img = img.astype(np.float32)\n","        img = np.atleast_3d(img)\n","\n","        means = [103.939, 116.779, 123.68]\n","\n","        for i in range(min(img.shape[2], len(means))):\n","            img[:, :, i] -= means[i]\n","\n","        img = img[:, :, ::-1]\n","    elif imgNorm == \"divide\":\n","        img = cv2.resize(img, (width, height))\n","        img = img.astype(np.float32)\n","        img = img/255.0\n","\n","    if ordering == 'channels_first':\n","        img = np.rollaxis(img, 2, 0)\n","    return img\n","\n","\n","def get_segmentation_array(image_input, nClasses,\n","                           width, height, no_reshape=False, read_image_type=1):\n","    \"\"\" Load segmentation array from input \"\"\"\n","\n","    seg_labels = np.zeros((height, width, nClasses))\n","\n","    if type(image_input) is np.ndarray:\n","        # It is already an array, use it as it is\n","        img = image_input\n","    elif isinstance(image_input, six.string_types):\n","        if not os.path.isfile(image_input):\n","            raise DataLoaderError(\"get_segmentation_array: \"\n","                                  \"path {0} doesn't exist\".format(image_input))\n","        img = cv2.imread(image_input, read_image_type)\n","    else:\n","        raise DataLoaderError(\"get_segmentation_array: \"\n","                              \"Can't process input type {0}\"\n","                              .format(str(type(image_input))))\n","\n","    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n","    img = img[:, :, 0]\n","\n","    for c in range(nClasses):\n","        seg_labels[:, :, c] = (img == c).astype(int)\n","\n","    if not no_reshape:\n","        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n","\n","    return seg_labels\n","\n","\n","def verify_segmentation_dataset(images_path, segs_path, n_classes, show_all_errors=False):\n","    # try:\n","      img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n","      if not len(img_seg_pairs):\n","          print(\n","              \"Couldn't load any data from images_path: \"\n","              \"{0} and segmentations path: {1}\".format(images_path, segs_path)\n","          )\n","          return False\n","\n","      return_value = True\n","      for im_fn, seg_fn in tqdm(img_seg_pairs):\n","          img = cv2.imread(im_fn)\n","          seg = cv2.imread(seg_fn)\n","          # seg = seg/255.0\n","          # Check dimensions match\n","          if not img.shape == seg.shape:\n","              return_value = False\n","              print(\n","                  \"The size of image {0} and its segmentation {1} \"\n","                  \"doesn't match (possibly the files are corrupt).\".format(\n","                      im_fn, seg_fn\n","                  )\n","              )\n","              if not show_all_errors:\n","                  break\n","          # else:\n","          #     max_pixel_value = np.max(seg[:, :, 0])\n","          #     if max_pixel_value >= n_classes:\n","          #         return_value = False\n","          #         print(\n","          #             \"The pixel values of the segmentation image {0} \"\n","          #             \"violating range [0, {1}]. \"\n","          #             \"Found maximum pixel value {2}\".format(\n","          #                 seg_fn, str(n_classes - 1), max_pixel_value\n","          #             )\n","          #         )\n","          #         if not show_all_errors:\n","          #             break\n","      if return_value:\n","          print(\"Dataset verified! \")\n","      else:\n","          print(\"Dataset not verified!\")\n","      return return_value\n","    # except DataLoaderError as e:\n","    #     print(\"Found error during data loading\\n{0}\".format(str(e)))\n","    #     return False\n","\n","def image_segmentation_generator(images_path, segs_path, batch_size,\n","                                 n_classes, input_height, input_width,\n","                                 output_height, output_width,\n","                                 do_augment=False,\n","                                 augmentation_name=\"aug_all\",\n","                                 custom_augmentation=None,\n","                                 other_inputs_paths=None, preprocessing=None,\n","                                 read_image_type=cv2.IMREAD_COLOR , ignore_segs=False ):\n","    \n","    if not ignore_segs:\n","        img_seg_pairs = get_pairs_from_paths(images_path, segs_path, other_inputs_paths=other_inputs_paths)\n","        random.shuffle(img_seg_pairs)\n","        zipped = itertools.cycle(img_seg_pairs)\n","    else:\n","        img_list = get_image_list_from_path(images_path)\n","        random.shuffle( img_list )\n","        img_list_gen = itertools.cycle(img_list)\n","\n","\n","    while True:\n","        X = []\n","        Y = []\n","        for _ in range(batch_size):\n","            if other_inputs_paths is None:\n","\n","                if ignore_segs:\n","                    im = next( img_list_gen )\n","                    seg = None \n","                else:\n","                    im, seg = next(zipped)\n","                    seg = cv2.imread(seg, 1)\n","\n","                im = cv2.imread(im, read_image_type)\n","                \n","                if do_augment:\n","\n","                    assert ignore_segs == False , \"Not supported yet\"\n","\n","                    if custom_augmentation is None:\n","                        im, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n","                                                       augmentation_name)\n","                    else:\n","                        im, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n","                                                              custom_augmentation)\n","\n","                if preprocessing is not None:\n","                    im = preprocessing(im)\n","\n","                X.append(get_image_array(im, input_width,\n","                                         input_height, ordering=IMAGE_ORDERING))\n","            else:\n","\n","                assert ignore_segs == False , \"Not supported yet\"\n","\n","                im, seg, others = next(zipped)\n","\n","                im = cv2.imread(im, read_image_type)\n","                seg = cv2.imread(seg, 1)\n","\n","                oth = []\n","                for f in others:\n","                    oth.append(cv2.imread(f, read_image_type))\n","\n","                if do_augment:\n","                    if custom_augmentation is None:\n","                        ims, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n","                                                        augmentation_name, other_imgs=oth)\n","                    else:\n","                        ims, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n","                                                               custom_augmentation, other_imgs=oth)\n","                else:\n","                    ims = [im]\n","                    ims.extend(oth)\n","\n","                oth = []\n","                for i, image in enumerate(ims):\n","                    oth_im = get_image_array(image, input_width,\n","                                             input_height, ordering=IMAGE_ORDERING)\n","\n","                    if preprocessing is not None:\n","                        if isinstance(preprocessing, Sequence):\n","                            oth_im = preprocessing[i](oth_im)\n","                        else:\n","                            oth_im = preprocessing(oth_im)\n","\n","                    oth.append(oth_im)\n","\n","                X.append(oth)\n","\n","            if not ignore_segs:\n","                Y.append(get_segmentation_array(\n","                    seg, n_classes, output_width, output_height))\n","\n","        if ignore_segs:\n","            yield np.array(X)\n","        else:\n","            yield np.array(X), np.array(Y)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660117461390,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"S5iPwLj1cwCG"},"outputs":[],"source":["import keras\n","import tensorflow as tf\n","from tqdm import tqdm \n","import numpy as np\n","import six \n","import os \n","import json \n","import sys \n","\n","from keras.models import Model \n","\n","def get_pariwise_similarities( feats ):\n","    feats_i = tf.reshape( feats , (-1 , 1 , feats.shape[1]*feats.shape[2] , feats.shape[3]))\n","    feats_j = tf.reshape( feats , (-1 ,  feats.shape[1]*feats.shape[2] , 1 , feats.shape[3]))\n","    \n","    feats_i = feats_i / (( tf.reduce_sum(feats_i**2 , axis=-1 ) )**(0.5))[ ... , None ]\n","    feats_j = feats_j / (( tf.reduce_sum(feats_j**2 , axis=-1 ) )**(0.5))[ ... , None ]\n","    \n","    feats_ixj = feats_i*feats_j\n","    \n","    return tf.reduce_sum( feats_ixj , axis=-1  )\n","      \n","def pairwise_dist_loss( feats_t , feats_s ):\n","    \n","    # todo max POOL     \n","    pool_factor = 4\n","    \n","    feats_t = tf.nn.max_pool(feats_t , (pool_factor,pool_factor) , strides=(pool_factor,pool_factor) , padding=\"VALID\" )\n","    feats_s = tf.nn.max_pool(feats_s , (pool_factor,pool_factor) , strides=(pool_factor,pool_factor) , padding=\"VALID\" )\n","            \n","    sims_t  = get_pariwise_similarities( feats_t )\n","    sims_s = get_pariwise_similarities( feats_s )\n","    n_pixs = sims_s.shape[1]\n","    \n","    return tf.reduce_sum(tf.reduce_sum(((sims_t - sims_s )**2 ) , axis=1), axis=1)/(n_pixs**2 )\n","\n","class Distiller(keras.Model):\n","    def __init__(self, student, teacher , distilation_loss , feats_distilation_loss=None , feats_distilation_loss_w=0.1   ):\n","        super(Distiller, self).__init__()\n","        self.teacher = teacher\n","        self.student = student\n","        self.distilation_loss = distilation_loss\n","        \n","        self.feats_distilation_loss = feats_distilation_loss \n","        self.feats_distilation_loss_w = feats_distilation_loss_w \n","        \n","        if not feats_distilation_loss is None:\n","            try:\n","                s_feat_out = student.get_layer(\"seg_feats\").output\n","            except:\n","                s_feat_out = student.get_layer(student.seg_feats_layer_name ).output\n","            try:\n","                t_feat_out = teacher.get_layer(\"seg_feats\").output \n","            except:\n","                t_feat_out = teacher.get_layer(teacher.seg_feats_layer_name ).output\n","            \n","            \n","            self.student_feat_model = Model( student.input , s_feat_out  )\n","            self.teacher_feat_model = Model( teacher.input , t_feat_out  )\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","\n","    ):\n","        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n","\n","\n","    def train_step(self, data):\n","        teacher_input ,  = data \n","        \n","        student_input = tf.image.resize( teacher_input , ( self.student.input_height , self.student.input_width ) )\n","\n","        teacher_predictions = self.teacher(teacher_input, training=False)\n","        teacher_predictions_reshape = tf.reshape(teacher_predictions , ((-1   , self.teacher.output_height , self.teacher.output_width , self.teacher.output_shape[-1])))\n","        \n","        \n","        if not self.feats_distilation_loss is None:\n","            teacher_feats = self.teacher_feat_model(teacher_input, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            student_predictions = self.student( student_input , training=True)\n","            student_predictions_resize = tf.reshape(student_predictions , ((-1, self.student.output_height , self.student.output_width , self.student.output_shape[-1])))\n","            student_predictions_resize = tf.image.resize( student_predictions_resize , ( self.teacher.output_height , self.teacher.output_width ) )\n","            \n","            loss = self.distilation_loss( teacher_predictions_reshape , student_predictions_resize )\n","            \n","            if not self.feats_distilation_loss is None:\n","                student_feats = self.student_feat_model( student_input , training=True)\n","                student_feats_resize = tf.image.resize( student_feats , ( teacher_feats.shape[1] , teacher_feats.shape[2] ) )\n","                loss += self.feats_distilation_loss_w*self.feats_distilation_loss( teacher_feats , student_feats_resize )\n","            \n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        self.compiled_metrics.update_state(teacher_predictions_reshape , student_predictions_resize )\n","        \n","\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {  \"distillation_loss\": loss}\n","        )\n","        return results"]},{"cell_type":"markdown","metadata":{"id":"WNTsTuUmneRM"},"source":["#### Moving to the locals files "]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660117461391,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"UwIBJlwRky8R"},"outputs":[],"source":["import sys\n","pathg = '/content/drive/My Drive/mobilenet/'\n","sys.path.append(pathg)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660117461392,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"0IkioYI8uuqg"},"outputs":[],"source":["lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 *10 **(epoch/20))"]},{"cell_type":"markdown","metadata":{"id":"ZHS-OudIrold"},"source":["# Model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5699,"status":"ok","timestamp":1660117467082,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"4ipVfMYXjfhH"},"outputs":[],"source":["\n","from keras.models import *\n","from keras.layers import *\n","import json\n","import os\n","import six\n","from keras.callbacks import Callback\n","from keras.callbacks import ModelCheckpoint\n","import tensorflow as tf\n","import glob\n","import sys\n","from keras_segmentation.models.mobilenet import get_mobilenet_encoder"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1660117467084,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"ywD8xceCpVZJ"},"outputs":[],"source":["if IMAGE_ORDERING == 'channels_first':\n","    MERGE_AXIS = 1\n","elif IMAGE_ORDERING == 'channels_last':\n","    MERGE_AXIS = -1"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1660117467085,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"dzc0Gd3ynUE1"},"outputs":[],"source":["def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n","          input_width=608, channels=3):\n","\n","    img_input, levels = encoder(\n","        input_height=input_height, input_width=input_width, channels=channels)\n","    [f1, f2, f3, f4, f5] = levels\n","\n","    o = f4\n","\n","    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n","    o = (Conv2D(512, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n","    o = (BatchNormalization())(o)\n","\n","    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n","    o = (concatenate([o, f3], axis=MERGE_AXIS))\n","    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n","    o = (Conv2D(256, (3, 3), padding='valid', activation='relu' , data_format=IMAGE_ORDERING))(o)\n","    o = (BatchNormalization())(o)\n","\n","    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n","    o = (concatenate([o, f2], axis=MERGE_AXIS))\n","    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n","    o = (Conv2D(128, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n","    o = (BatchNormalization())(o)\n","\n","    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n","\n","    if l1_skip_conn:\n","        o = (concatenate([o, f1], axis=MERGE_AXIS))\n","\n","    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n","    o = (Conv2D(64, (3, 3), padding='valid', activation='relu', data_format=IMAGE_ORDERING, name=\"seg_feats\"))(o)\n","    o = (BatchNormalization())(o)\n","\n","    o = Conv2D(n_classes, (3, 3), padding='same',\n","               data_format=IMAGE_ORDERING)(o)\n","\n","    model = get_segmentation_model(img_input, o)\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1660117467086,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"lOJhhXEFqs9P"},"outputs":[],"source":["def get_segmentation_model(input, output):\n","    img_input = input\n","    o = output\n","    o_shape = Model(img_input, o).output_shape\n","    i_shape = Model(img_input, o).input_shape\n","    \n","    if IMAGE_ORDERING == 'channels_first':\n","        output_height = o_shape[2]\n","        output_width = o_shape[3]\n","        input_height = i_shape[2]\n","        input_width = i_shape[3]\n","        n_classes = o_shape[1]\n","        o = (Reshape((-1, output_height*output_width)))(o)\n","        o = (Permute((2, 1)))(o)\n","    elif IMAGE_ORDERING == 'channels_last':\n","        output_height = o_shape[1]\n","        output_width = o_shape[2]\n","        input_height = i_shape[1]\n","        input_width = i_shape[2]\n","        n_classes = o_shape[3]\n","        o = (Reshape((output_height*output_width, -1)))(o)\n","\n","    o = (Activation('sigmoid'))(o)   #sigmoid\n","    model = Model(img_input, o)\n","    model.output_width = output_width\n","    model.output_height = output_height\n","    model.n_classes = n_classes\n","    model.input_height = input_height\n","    model.input_width = input_width\n","    return model\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1660117467088,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"CinKurFUnOSW"},"outputs":[],"source":["def mobilenet_unet(n_classes, input_height=224, input_width=224,\n","                   encoder_level=3, channels=3):\n","\n","    model = _unet(n_classes, get_mobilenet_encoder,\n","                  input_height=input_height, input_width=input_width, channels=channels)\n","    model.model_name = \"mobilenet_unet\"\n","    return model"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7967,"status":"ok","timestamp":1660117475009,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"0VKzrpgOonIU","outputId":"8a229633-5e73-404e-9a19-6eb61ceae58b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n","17227776/17225924 [==============================] - 0s 0us/step\n","17235968/17225924 [==============================] - 0s 0us/step\n"]}],"source":["model = mobilenet_unet(n_classes=2, input_height=1024, input_width=1024,encoder_level=3, channels=3)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1660117475009,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"4brP7VQgTM8w"},"outputs":[],"source":["def resize_image(inp,  s, data_format):\n","\n","    try:\n","        return Lambda(lambda x: K.resize_images(x,\n","                                                height_factor=s[0],\n","                                                width_factor=s[1],\n","                                                data_format=data_format,\n","                                                interpolation='bilinear'))(inp)\n","\n","    except Exception as e:\n","        # if keras is old, then rely on the tf function\n","        # Sorry theano/cntk users!!!\n","        assert data_format == 'channels_last'\n","        assert IMAGE_ORDERING == 'channels_last'\n","\n","        import tensorflow as tf\n","\n","        return Lambda(\n","            lambda x: tf.image.resize_images(\n","                x, (K.int_shape(x)[1]*s[0], K.int_shape(x)[2]*s[1]))\n","        )(inp)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":501,"status":"ok","timestamp":1660117475010,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"KbZ0WDr_16Uv","outputId":"17a7b20f-5705-488f-ae56-dac605d144ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 1024, 1024,  0           []                               \n","                                 3)]                                                              \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 1026, 1026,   0           ['input_1[0][0]']                \n","                                3)                                                                \n","                                                                                                  \n"," conv1 (Conv2D)                 (None, 512, 512, 32  864         ['conv1_pad[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv1_bn (BatchNormalization)  (None, 512, 512, 32  128         ['conv1[0][0]']                  \n","                                )                                                                 \n","                                                                                                  \n"," conv1_relu (Activation)        (None, 512, 512, 32  0           ['conv1_bn[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," conv_pad_1 (ZeroPadding2D)     (None, 514, 514, 32  0           ['conv1_relu[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," conv_dw_1 (DepthwiseConv2D)    (None, 512, 512, 32  288         ['conv_pad_1[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," conv_dw_1_bn (BatchNormalizati  (None, 512, 512, 32  128        ['conv_dw_1[0][0]']              \n"," on)                            )                                                                 \n","                                                                                                  \n"," conv_dw_1_relu (Activation)    (None, 512, 512, 32  0           ['conv_dw_1_bn[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv_pw_1 (Conv2D)             (None, 512, 512, 64  2048        ['conv_dw_1_relu[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," conv_pw_1_bn (BatchNormalizati  (None, 512, 512, 64  256        ['conv_pw_1[0][0]']              \n"," on)                            )                                                                 \n","                                                                                                  \n"," conv_pw_1_relu (Activation)    (None, 512, 512, 64  0           ['conv_pw_1_bn[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv_pad_2 (ZeroPadding2D)     (None, 514, 514, 64  0           ['conv_pw_1_relu[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," conv_dw_2 (DepthwiseConv2D)    (None, 256, 256, 64  576         ['conv_pad_2[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," conv_dw_2_bn (BatchNormalizati  (None, 256, 256, 64  256        ['conv_dw_2[0][0]']              \n"," on)                            )                                                                 \n","                                                                                                  \n"," conv_dw_2_relu (Activation)    (None, 256, 256, 64  0           ['conv_dw_2_bn[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv_pw_2 (Conv2D)             (None, 256, 256, 12  8192        ['conv_dw_2_relu[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," conv_pw_2_bn (BatchNormalizati  (None, 256, 256, 12  512        ['conv_pw_2[0][0]']              \n"," on)                            8)                                                                \n","                                                                                                  \n"," conv_pw_2_relu (Activation)    (None, 256, 256, 12  0           ['conv_pw_2_bn[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," conv_pad_3 (ZeroPadding2D)     (None, 258, 258, 12  0           ['conv_pw_2_relu[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," conv_dw_3 (DepthwiseConv2D)    (None, 256, 256, 12  1152        ['conv_pad_3[0][0]']             \n","                                8)                                                                \n","                                                                                                  \n"," conv_dw_3_bn (BatchNormalizati  (None, 256, 256, 12  512        ['conv_dw_3[0][0]']              \n"," on)                            8)                                                                \n","                                                                                                  \n"," conv_dw_3_relu (Activation)    (None, 256, 256, 12  0           ['conv_dw_3_bn[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," conv_pw_3 (Conv2D)             (None, 256, 256, 12  16384       ['conv_dw_3_relu[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," conv_pw_3_bn (BatchNormalizati  (None, 256, 256, 12  512        ['conv_pw_3[0][0]']              \n"," on)                            8)                                                                \n","                                                                                                  \n"," conv_pw_3_relu (Activation)    (None, 256, 256, 12  0           ['conv_pw_3_bn[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," conv_pad_4 (ZeroPadding2D)     (None, 258, 258, 12  0           ['conv_pw_3_relu[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," conv_dw_4 (DepthwiseConv2D)    (None, 128, 128, 12  1152        ['conv_pad_4[0][0]']             \n","                                8)                                                                \n","                                                                                                  \n"," conv_dw_4_bn (BatchNormalizati  (None, 128, 128, 12  512        ['conv_dw_4[0][0]']              \n"," on)                            8)                                                                \n","                                                                                                  \n"," conv_dw_4_relu (Activation)    (None, 128, 128, 12  0           ['conv_dw_4_bn[0][0]']           \n","                                8)                                                                \n","                                                                                                  \n"," conv_pw_4 (Conv2D)             (None, 128, 128, 25  32768       ['conv_dw_4_relu[0][0]']         \n","                                6)                                                                \n","                                                                                                  \n"," conv_pw_4_bn (BatchNormalizati  (None, 128, 128, 25  1024       ['conv_pw_4[0][0]']              \n"," on)                            6)                                                                \n","                                                                                                  \n"," conv_pw_4_relu (Activation)    (None, 128, 128, 25  0           ['conv_pw_4_bn[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," conv_pad_5 (ZeroPadding2D)     (None, 130, 130, 25  0           ['conv_pw_4_relu[0][0]']         \n","                                6)                                                                \n","                                                                                                  \n"," conv_dw_5 (DepthwiseConv2D)    (None, 128, 128, 25  2304        ['conv_pad_5[0][0]']             \n","                                6)                                                                \n","                                                                                                  \n"," conv_dw_5_bn (BatchNormalizati  (None, 128, 128, 25  1024       ['conv_dw_5[0][0]']              \n"," on)                            6)                                                                \n","                                                                                                  \n"," conv_dw_5_relu (Activation)    (None, 128, 128, 25  0           ['conv_dw_5_bn[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," conv_pw_5 (Conv2D)             (None, 128, 128, 25  65536       ['conv_dw_5_relu[0][0]']         \n","                                6)                                                                \n","                                                                                                  \n"," conv_pw_5_bn (BatchNormalizati  (None, 128, 128, 25  1024       ['conv_pw_5[0][0]']              \n"," on)                            6)                                                                \n","                                                                                                  \n"," conv_pw_5_relu (Activation)    (None, 128, 128, 25  0           ['conv_pw_5_bn[0][0]']           \n","                                6)                                                                \n","                                                                                                  \n"," conv_pad_6 (ZeroPadding2D)     (None, 130, 130, 25  0           ['conv_pw_5_relu[0][0]']         \n","                                6)                                                                \n","                                                                                                  \n"," conv_dw_6 (DepthwiseConv2D)    (None, 64, 64, 256)  2304        ['conv_pad_6[0][0]']             \n","                                                                                                  \n"," conv_dw_6_bn (BatchNormalizati  (None, 64, 64, 256)  1024       ['conv_dw_6[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_dw_6_relu (Activation)    (None, 64, 64, 256)  0           ['conv_dw_6_bn[0][0]']           \n","                                                                                                  \n"," conv_pw_6 (Conv2D)             (None, 64, 64, 512)  131072      ['conv_dw_6_relu[0][0]']         \n","                                                                                                  \n"," conv_pw_6_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_pw_6[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_pw_6_relu (Activation)    (None, 64, 64, 512)  0           ['conv_pw_6_bn[0][0]']           \n","                                                                                                  \n"," conv_pad_7 (ZeroPadding2D)     (None, 66, 66, 512)  0           ['conv_pw_6_relu[0][0]']         \n","                                                                                                  \n"," conv_dw_7 (DepthwiseConv2D)    (None, 64, 64, 512)  4608        ['conv_pad_7[0][0]']             \n","                                                                                                  \n"," conv_dw_7_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_dw_7[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_dw_7_relu (Activation)    (None, 64, 64, 512)  0           ['conv_dw_7_bn[0][0]']           \n","                                                                                                  \n"," conv_pw_7 (Conv2D)             (None, 64, 64, 512)  262144      ['conv_dw_7_relu[0][0]']         \n","                                                                                                  \n"," conv_pw_7_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_pw_7[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_pw_7_relu (Activation)    (None, 64, 64, 512)  0           ['conv_pw_7_bn[0][0]']           \n","                                                                                                  \n"," conv_pad_8 (ZeroPadding2D)     (None, 66, 66, 512)  0           ['conv_pw_7_relu[0][0]']         \n","                                                                                                  \n"," conv_dw_8 (DepthwiseConv2D)    (None, 64, 64, 512)  4608        ['conv_pad_8[0][0]']             \n","                                                                                                  \n"," conv_dw_8_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_dw_8[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_dw_8_relu (Activation)    (None, 64, 64, 512)  0           ['conv_dw_8_bn[0][0]']           \n","                                                                                                  \n"," conv_pw_8 (Conv2D)             (None, 64, 64, 512)  262144      ['conv_dw_8_relu[0][0]']         \n","                                                                                                  \n"," conv_pw_8_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_pw_8[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_pw_8_relu (Activation)    (None, 64, 64, 512)  0           ['conv_pw_8_bn[0][0]']           \n","                                                                                                  \n"," conv_pad_9 (ZeroPadding2D)     (None, 66, 66, 512)  0           ['conv_pw_8_relu[0][0]']         \n","                                                                                                  \n"," conv_dw_9 (DepthwiseConv2D)    (None, 64, 64, 512)  4608        ['conv_pad_9[0][0]']             \n","                                                                                                  \n"," conv_dw_9_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_dw_9[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_dw_9_relu (Activation)    (None, 64, 64, 512)  0           ['conv_dw_9_bn[0][0]']           \n","                                                                                                  \n"," conv_pw_9 (Conv2D)             (None, 64, 64, 512)  262144      ['conv_dw_9_relu[0][0]']         \n","                                                                                                  \n"," conv_pw_9_bn (BatchNormalizati  (None, 64, 64, 512)  2048       ['conv_pw_9[0][0]']              \n"," on)                                                                                              \n","                                                                                                  \n"," conv_pw_9_relu (Activation)    (None, 64, 64, 512)  0           ['conv_pw_9_bn[0][0]']           \n","                                                                                                  \n"," conv_pad_10 (ZeroPadding2D)    (None, 66, 66, 512)  0           ['conv_pw_9_relu[0][0]']         \n","                                                                                                  \n"," conv_dw_10 (DepthwiseConv2D)   (None, 64, 64, 512)  4608        ['conv_pad_10[0][0]']            \n","                                                                                                  \n"," conv_dw_10_bn (BatchNormalizat  (None, 64, 64, 512)  2048       ['conv_dw_10[0][0]']             \n"," ion)                                                                                             \n","                                                                                                  \n"," conv_dw_10_relu (Activation)   (None, 64, 64, 512)  0           ['conv_dw_10_bn[0][0]']          \n","                                                                                                  \n"," conv_pw_10 (Conv2D)            (None, 64, 64, 512)  262144      ['conv_dw_10_relu[0][0]']        \n","                                                                                                  \n"," conv_pw_10_bn (BatchNormalizat  (None, 64, 64, 512)  2048       ['conv_pw_10[0][0]']             \n"," ion)                                                                                             \n","                                                                                                  \n"," conv_pw_10_relu (Activation)   (None, 64, 64, 512)  0           ['conv_pw_10_bn[0][0]']          \n","                                                                                                  \n"," conv_pad_11 (ZeroPadding2D)    (None, 66, 66, 512)  0           ['conv_pw_10_relu[0][0]']        \n","                                                                                                  \n"," conv_dw_11 (DepthwiseConv2D)   (None, 64, 64, 512)  4608        ['conv_pad_11[0][0]']            \n","                                                                                                  \n"," conv_dw_11_bn (BatchNormalizat  (None, 64, 64, 512)  2048       ['conv_dw_11[0][0]']             \n"," ion)                                                                                             \n","                                                                                                  \n"," conv_dw_11_relu (Activation)   (None, 64, 64, 512)  0           ['conv_dw_11_bn[0][0]']          \n","                                                                                                  \n"," conv_pw_11 (Conv2D)            (None, 64, 64, 512)  262144      ['conv_dw_11_relu[0][0]']        \n","                                                                                                  \n"," conv_pw_11_bn (BatchNormalizat  (None, 64, 64, 512)  2048       ['conv_pw_11[0][0]']             \n"," ion)                                                                                             \n","                                                                                                  \n"," conv_pw_11_relu (Activation)   (None, 64, 64, 512)  0           ['conv_pw_11_bn[0][0]']          \n","                                                                                                  \n"," zero_padding2d (ZeroPadding2D)  (None, 66, 66, 512)  0          ['conv_pw_11_relu[0][0]']        \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 64, 64, 512)  2359808     ['zero_padding2d[0][0]']         \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 64, 64, 512)  2048       ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 128, 128, 51  0           ['batch_normalization[0][0]']    \n","                                2)                                                                \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 128, 128, 76  0           ['up_sampling2d[0][0]',          \n","                                8)                                'conv_pw_5_relu[0][0]']         \n","                                                                                                  \n"," zero_padding2d_1 (ZeroPadding2  (None, 130, 130, 76  0          ['concatenate[0][0]']            \n"," D)                             8)                                                                \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 128, 128, 25  1769728     ['zero_padding2d_1[0][0]']       \n","                                6)                                                                \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_1[0][0]']               \n"," rmalization)                   6)                                                                \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 25  0          ['batch_normalization_1[0][0]']  \n","                                6)                                                                \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256, 256, 38  0           ['up_sampling2d_1[0][0]',        \n","                                4)                                'conv_pw_3_relu[0][0]']         \n","                                                                                                  \n"," zero_padding2d_2 (ZeroPadding2  (None, 258, 258, 38  0          ['concatenate_1[0][0]']          \n"," D)                             4)                                                                \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 256, 256, 12  442496      ['zero_padding2d_2[0][0]']       \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n"," rmalization)                   8)                                                                \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 12  0          ['batch_normalization_2[0][0]']  \n","                                8)                                                                \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 512, 512, 19  0           ['up_sampling2d_2[0][0]',        \n","                                2)                                'conv_pw_1_relu[0][0]']         \n","                                                                                                  \n"," zero_padding2d_3 (ZeroPadding2  (None, 514, 514, 19  0          ['concatenate_2[0][0]']          \n"," D)                             2)                                                                \n","                                                                                                  \n"," seg_feats (Conv2D)             (None, 512, 512, 64  110656      ['zero_padding2d_3[0][0]']       \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 512, 512, 64  256        ['seg_feats[0][0]']              \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 512, 512, 2)  1154        ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," reshape (Reshape)              (None, 262144, 2)    0           ['conv2d_3[0][0]']               \n","                                                                                                  \n"," activation (Activation)        (None, 262144, 2)    0           ['reshape[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 6,315,522\n","Trainable params: 6,298,882\n","Non-trainable params: 16,640\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660117475011,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"Sf7-GL6vVWDs"},"outputs":[],"source":["def masked_categorical_crossentropy(gt, pr):\n","    from keras.losses import categorical_crossentropy\n","    mask = 1 - gt[:, :, 0]\n","    return categorical_crossentropy(gt, pr) * mask"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1660117475012,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"akpGIy6tVaaY"},"outputs":[],"source":["\n","def find_latest_checkpoint(checkpoints_path, fail_safe=True):\n","\n","    # This is legacy code, there should always be a \"checkpoint\" file in your directory\n","\n","    def get_epoch_number_from_path(path):\n","        return path.replace(checkpoints_path, \"\").strip(\".\")\n","\n","    # Get all matching files\n","    all_checkpoint_files = glob.glob(checkpoints_path + \".*\")\n","    if len(all_checkpoint_files) == 0:\n","        all_checkpoint_files = glob.glob(checkpoints_path + \"*.*\")\n","    all_checkpoint_files = [ff.replace(\".index\", \"\") for ff in\n","                            all_checkpoint_files]  # to make it work for newer versions of keras\n","    # Filter out entries where the epoc_number part is pure number\n","    all_checkpoint_files = list(filter(lambda f: get_epoch_number_from_path(f)\n","                                       .isdigit(), all_checkpoint_files))\n","    \n","    if not len(all_checkpoint_files):\n","        # The glob list is empty, don't have a checkpoints_path\n","        if not fail_safe:\n","            raise ValueError(\"Checkpoint path {0} invalid\"\n","                             .format(checkpoints_path))\n","        else:\n","            return None"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1660117475012,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"wH9C0D2GokpP"},"outputs":[],"source":["from tensorflow.keras import models, layers, regularizers\n","from tensorflow.keras import backend as K\n","\n","''' A few useful metrics and losses'''\n","\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n","\n","def jacard_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n","\n","def jacard_coef_loss(y_true, y_pred):\n","    return -jacard_coef(y_true, y_pred)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"wP6u5Uxlcwos"},"source":["# Training "]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1660117475013,"user":{"displayName":"Hubert Kanyamahanga","userId":"18324049232410608853"},"user_tz":0},"id":"bfEygA7EuQsQ"},"outputs":[],"source":["class CheckpointsCallback(Callback):\n","    def __init__(self, checkpoints_path):\n","        self.checkpoints_path = checkpoints_path\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if self.checkpoints_path is not None:\n","            self.model.save_weights(self.checkpoints_path + \".\" + str(epoch)+'.h5')\n","            print(\"saved \", self.checkpoints_path + \".\" + str(epoch)+'.h5')\n","\n","\n","def train(model,\n","          train_images,\n","          train_annotations,\n","          input_height=None,\n","          input_width=None,\n","          n_classes=None,\n","          verify_dataset=True,\n","          checkpoints_path=None,\n","          epochs=5,\n","          batch_size=2,\n","          validate=False,\n","          val_images=None,\n","          val_annotations=None,\n","          val_batch_size=2,\n","          auto_resume_checkpoint=False,\n","          load_weights=None,\n","          steps_per_epoch=512,\n","          val_steps_per_epoch=512,\n","          gen_use_multiprocessing=False,\n","          ignore_zero_class=False,\n","          optimizer_name='adam',\n","          do_augment=False,\n","          augmentation_name=\"aug_all\",\n","          callbacks=None,\n","          custom_augmentation=None,\n","          other_inputs_paths=None,\n","          preprocessing=None,\n","          read_image_type=1  # cv2.IMREAD_COLOR = 1 (rgb),\n","                             # cv2.IMREAD_GRAYSCALE = 0,\n","                             # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n","         ):\n","\n","    n_classes = model.n_classes\n","    input_height = model.input_height\n","    input_width = model.input_width\n","    output_height = model.output_height\n","    output_width = model.output_width\n","\n","    if validate:\n","        assert val_images is not None\n","        assert val_annotations is not None\n","\n","    if optimizer_name is not None:\n","        if ignore_zero_class:\n","            loss_k = masked_categorical_crossentropy\n","        else:\n","            loss_k = 'categorical_crossentropy'\n","        #model.compile(loss=loss_k,optimizer=optimizer_name,metrics=['accuracy'])\n","        model.compile(loss=loss_k,optimizer=optimizer_name, metrics = ['accuracy', Precision(), Recall(), dice_coef, jacard_coef])\n","    if checkpoints_path is not None:\n","        config_file = checkpoints_path + \"_config.json\"\n","        dir_name = os.path.dirname(config_file)\n","        if ( not os.path.exists(dir_name) )  and len( dir_name ) > 0 :\n","            os.makedirs(dir_name)\n","\n","        with open(config_file, \"w\") as f:\n","            json.dump({\n","                \"model_class\": model.model_name,\n","                \"n_classes\": n_classes,\n","                \"input_height\": input_height,\n","                \"input_width\": input_width,\n","                \"output_height\": output_height,\n","                \"output_width\": output_width\n","            }, f)\n","\n","    if load_weights is not None and len(load_weights) > 0:\n","        print(\"Loading weights from \", load_weights)\n","        model.load_weights(load_weights)\n","\n","    initial_epoch = 0\n","\n","    if auto_resume_checkpoint and (checkpoints_path is not None):\n","        latest_checkpoint = find_latest_checkpoint(checkpoints_path)\n","        if latest_checkpoint is not None:\n","            print(\"Loading the weights from latest checkpoint \",\n","                  latest_checkpoint)\n","            model.load_weights(latest_checkpoint)\n","\n","            initial_epoch = int(latest_checkpoint.split('.')[-1])\n","\n","    if verify_dataset:\n","        print(\"Verifying training dataset\")\n","        verified = verify_segmentation_dataset(train_images,\n","                                               train_annotations,\n","                                               n_classes)\n","        assert verified\n","        if validate:\n","            print(\"Verifying validation dataset\")\n","            verified = verify_segmentation_dataset(val_images,\n","                                                   val_annotations,\n","                                                   n_classes)\n","            assert verified\n","\n","    train_gen = image_segmentation_generator(\n","        train_images, train_annotations,  batch_size,  n_classes,\n","        input_height, input_width, output_height, output_width,\n","        do_augment=do_augment, augmentation_name=augmentation_name,\n","        custom_augmentation=custom_augmentation, other_inputs_paths=other_inputs_paths,\n","        preprocessing=preprocessing, read_image_type=read_image_type)\n","\n","    if validate:\n","        val_gen = image_segmentation_generator(\n","            val_images, val_annotations,  val_batch_size,\n","            n_classes, input_height, input_width, output_height, output_width,\n","            other_inputs_paths=other_inputs_paths,\n","            preprocessing=preprocessing, read_image_type=read_image_type)\n","\n","    if callbacks is None and (not checkpoints_path is  None) :\n","        default_callback = ModelCheckpoint(\n","                filepath=checkpoints_path + \".{epoch:05d}.h5\",\n","                save_weights_only=True,\n","                verbose=True\n","            )\n","\n","        if sys.version_info[0] < 3: # for pyhton 2 \n","            default_callback = CheckpointsCallback(checkpoints_path)\n","\n","        callbacks = [\n","            default_callback\n","        ]\n","\n","    if callbacks is None:\n","        callbacks = []\n","\n","    if not validate:\n","        k=model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n","                  epochs=epochs, callbacks=callbacks, initial_epoch=initial_epoch)\n","    else:\n","        k=model.fit(train_gen,\n","                  steps_per_epoch=steps_per_epoch,\n","                  validation_data=val_gen,\n","                  validation_steps=val_steps_per_epoch,\n","                  epochs=epochs, callbacks=callbacks,\n","                  use_multiprocessing=gen_use_multiprocessing, initial_epoch=initial_epoch)\n","    return k"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClzVgRuwdcmM","outputId":"3b13469b-af25-4d49-98f2-76e8acf01b05"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Verifying training dataset\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|| 177/177 [02:57<00:00,  1.00s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Dataset verified! \n","Verifying validation dataset\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|| 24/24 [00:58<00:00,  2.42s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Dataset verified! \n","Epoch 1/40\n","512/512 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.8564 - precision: 0.3693 - recall: 0.8243 - dice_coef: 0.5004 - jacard_coef: 0.3388\n","Epoch 1: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00001.h5\n","512/512 [==============================] - 400s 743ms/step - loss: 0.1359 - accuracy: 0.8564 - precision: 0.3693 - recall: 0.8243 - dice_coef: 0.5004 - jacard_coef: 0.3388 - val_loss: 0.0394 - val_accuracy: 0.9979 - val_precision: 0.3497 - val_recall: 0.9331 - val_dice_coef: 0.4902 - val_jacard_coef: 0.3275\n","Epoch 2/40\n","512/512 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9965 - precision: 0.4420 - recall: 0.8749 - dice_coef: 0.5751 - jacard_coef: 0.4058\n","Epoch 2: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00002.h5\n","512/512 [==============================] - 373s 729ms/step - loss: 0.1295 - accuracy: 0.9965 - precision: 0.4420 - recall: 0.8749 - dice_coef: 0.5751 - jacard_coef: 0.4058 - val_loss: 0.1264 - val_accuracy: 0.9982 - val_precision: 0.4106 - val_recall: 0.8734 - val_dice_coef: 0.5449 - val_jacard_coef: 0.3765\n","Epoch 3/40\n","512/512 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9974 - precision: 0.4660 - recall: 0.9070 - dice_coef: 0.6049 - jacard_coef: 0.4348\n","Epoch 3: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00003.h5\n","512/512 [==============================] - 373s 730ms/step - loss: 0.1266 - accuracy: 0.9974 - precision: 0.4660 - recall: 0.9070 - dice_coef: 0.6049 - jacard_coef: 0.4348 - val_loss: 0.2513 - val_accuracy: 0.9975 - val_precision: 0.4445 - val_recall: 0.7028 - val_dice_coef: 0.5456 - val_jacard_coef: 0.3774\n","Epoch 4/40\n","512/512 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9972 - precision: 0.4726 - recall: 0.9163 - dice_coef: 0.6140 - jacard_coef: 0.4439\n","Epoch 4: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00004.h5\n","512/512 [==============================] - 374s 730ms/step - loss: 0.2855 - accuracy: 0.9972 - precision: 0.4726 - recall: 0.9163 - dice_coef: 0.6140 - jacard_coef: 0.4439 - val_loss: 0.0277 - val_accuracy: 0.9983 - val_precision: 0.4229 - val_recall: 0.7681 - val_dice_coef: 0.5463 - val_jacard_coef: 0.3781\n","Epoch 5/40\n","512/512 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.9973 - precision: 0.4769 - recall: 0.9202 - dice_coef: 0.6200 - jacard_coef: 0.4500\n","Epoch 5: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00005.h5\n","512/512 [==============================] - 374s 731ms/step - loss: 0.4111 - accuracy: 0.9973 - precision: 0.4769 - recall: 0.9202 - dice_coef: 0.6200 - jacard_coef: 0.4500 - val_loss: 1.0718 - val_accuracy: 0.9970 - val_precision: 0.4212 - val_recall: 0.8283 - val_dice_coef: 0.5547 - val_jacard_coef: 0.3852\n","Epoch 6/40\n","512/512 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.9974 - precision: 0.4806 - recall: 0.9259 - dice_coef: 0.6258 - jacard_coef: 0.4559\n","Epoch 6: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00006.h5\n","512/512 [==============================] - 375s 734ms/step - loss: 0.5044 - accuracy: 0.9974 - precision: 0.4806 - recall: 0.9259 - dice_coef: 0.6258 - jacard_coef: 0.4559 - val_loss: 0.9554 - val_accuracy: 0.9976 - val_precision: 0.4155 - val_recall: 0.8106 - val_dice_coef: 0.5445 - val_jacard_coef: 0.3757\n","Epoch 7/40\n","512/512 [==============================] - ETA: 0s - loss: 0.5860 - accuracy: 0.9975 - precision: 0.4814 - recall: 0.9242 - dice_coef: 0.6264 - jacard_coef: 0.4565\n","Epoch 7: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00007.h5\n","512/512 [==============================] - 374s 731ms/step - loss: 0.5860 - accuracy: 0.9975 - precision: 0.4814 - recall: 0.9242 - dice_coef: 0.6264 - jacard_coef: 0.4565 - val_loss: 0.5700 - val_accuracy: 0.9978 - val_precision: 0.4269 - val_recall: 0.8059 - val_dice_coef: 0.5540 - val_jacard_coef: 0.3842\n","Epoch 8/40\n","512/512 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.9975 - precision: 0.4785 - recall: 0.9044 - dice_coef: 0.6201 - jacard_coef: 0.4500\n","Epoch 8: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00008.h5\n","512/512 [==============================] - 373s 728ms/step - loss: 0.6543 - accuracy: 0.9975 - precision: 0.4785 - recall: 0.9044 - dice_coef: 0.6201 - jacard_coef: 0.4500 - val_loss: 1.0565 - val_accuracy: 0.9977 - val_precision: 0.4296 - val_recall: 0.8101 - val_dice_coef: 0.5577 - val_jacard_coef: 0.3879\n","Epoch 9/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7186 - accuracy: 0.9975 - precision: 0.4855 - recall: 0.9283 - dice_coef: 0.6329 - jacard_coef: 0.4633\n","Epoch 9: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00009.h5\n","512/512 [==============================] - 374s 730ms/step - loss: 0.7186 - accuracy: 0.9975 - precision: 0.4855 - recall: 0.9283 - dice_coef: 0.6329 - jacard_coef: 0.4633 - val_loss: 0.8208 - val_accuracy: 0.9979 - val_precision: 0.4174 - val_recall: 0.8395 - val_dice_coef: 0.5499 - val_jacard_coef: 0.3808\n","Epoch 10/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.9975 - precision: 0.4848 - recall: 0.9225 - dice_coef: 0.6307 - jacard_coef: 0.4611\n","Epoch 10: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00010.h5\n","512/512 [==============================] - 372s 727ms/step - loss: 0.7584 - accuracy: 0.9975 - precision: 0.4848 - recall: 0.9225 - dice_coef: 0.6307 - jacard_coef: 0.4611 - val_loss: 1.1116 - val_accuracy: 0.9980 - val_precision: 0.4166 - val_recall: 0.8543 - val_dice_coef: 0.5539 - val_jacard_coef: 0.3843\n","Epoch 11/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.9975 - precision: 0.4855 - recall: 0.9229 - dice_coef: 0.6318 - jacard_coef: 0.4623\n","Epoch 11: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00011.h5\n","512/512 [==============================] - 374s 731ms/step - loss: 0.7789 - accuracy: 0.9975 - precision: 0.4855 - recall: 0.9229 - dice_coef: 0.6318 - jacard_coef: 0.4623 - val_loss: 1.1621 - val_accuracy: 0.9980 - val_precision: 0.4167 - val_recall: 0.8397 - val_dice_coef: 0.5461 - val_jacard_coef: 0.3775\n","Epoch 12/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.9975 - precision: 0.4862 - recall: 0.9224 - dice_coef: 0.6325 - jacard_coef: 0.4631\n","Epoch 12: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00012.h5\n","512/512 [==============================] - 374s 731ms/step - loss: 0.7850 - accuracy: 0.9975 - precision: 0.4862 - recall: 0.9224 - dice_coef: 0.6325 - jacard_coef: 0.4631 - val_loss: 0.6906 - val_accuracy: 0.9981 - val_precision: 0.4270 - val_recall: 0.8187 - val_dice_coef: 0.5594 - val_jacard_coef: 0.3896\n","Epoch 13/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.9976 - precision: 0.4863 - recall: 0.9219 - dice_coef: 0.6323 - jacard_coef: 0.4631\n","Epoch 13: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00013.h5\n","512/512 [==============================] - 372s 728ms/step - loss: 0.7789 - accuracy: 0.9976 - precision: 0.4863 - recall: 0.9219 - dice_coef: 0.6323 - jacard_coef: 0.4631 - val_loss: 0.0546 - val_accuracy: 0.9983 - val_precision: 0.4292 - val_recall: 0.7789 - val_dice_coef: 0.5513 - val_jacard_coef: 0.3823\n","Epoch 14/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.9976 - precision: 0.4867 - recall: 0.9158 - dice_coef: 0.6317 - jacard_coef: 0.4625\n","Epoch 14: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00014.h5\n","512/512 [==============================] - 372s 727ms/step - loss: 0.7743 - accuracy: 0.9976 - precision: 0.4867 - recall: 0.9158 - dice_coef: 0.6317 - jacard_coef: 0.4625 - val_loss: 1.1299 - val_accuracy: 0.9981 - val_precision: 0.4215 - val_recall: 0.8395 - val_dice_coef: 0.5557 - val_jacard_coef: 0.3863\n","Epoch 15/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.9976 - precision: 0.4868 - recall: 0.9140 - dice_coef: 0.6315 - jacard_coef: 0.4624\n","Epoch 15: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00015.h5\n","512/512 [==============================] - 373s 729ms/step - loss: 0.7622 - accuracy: 0.9976 - precision: 0.4868 - recall: 0.9140 - dice_coef: 0.6315 - jacard_coef: 0.4624 - val_loss: 0.9973 - val_accuracy: 0.9982 - val_precision: 0.4273 - val_recall: 0.8144 - val_dice_coef: 0.5591 - val_jacard_coef: 0.3895\n","Epoch 16/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7442 - accuracy: 0.9977 - precision: 0.4874 - recall: 0.9115 - dice_coef: 0.6313 - jacard_coef: 0.4626\n","Epoch 16: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00016.h5\n","512/512 [==============================] - 373s 729ms/step - loss: 0.7442 - accuracy: 0.9977 - precision: 0.4874 - recall: 0.9115 - dice_coef: 0.6313 - jacard_coef: 0.4626 - val_loss: 0.5726 - val_accuracy: 0.9982 - val_precision: 0.4327 - val_recall: 0.7931 - val_dice_coef: 0.5554 - val_jacard_coef: 0.3859\n","Epoch 17/40\n","512/512 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.9977 - precision: 0.4876 - recall: 0.9110 - dice_coef: 0.6315 - jacard_coef: 0.4627\n","Epoch 17: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00017.h5\n","512/512 [==============================] - 373s 729ms/step - loss: 0.7226 - accuracy: 0.9977 - precision: 0.4876 - recall: 0.9110 - dice_coef: 0.6315 - jacard_coef: 0.4627 - val_loss: 0.7491 - val_accuracy: 0.9981 - val_precision: 0.4189 - val_recall: 0.8517 - val_dice_coef: 0.5573 - val_jacard_coef: 0.3876\n","Epoch 18/40\n","512/512 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.9977 - precision: 0.4877 - recall: 0.9091 - dice_coef: 0.6303 - jacard_coef: 0.4620\n","Epoch 18: saving model to /content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet.00018.h5\n","512/512 [==============================] - 374s 730ms/step - loss: 0.6978 - accuracy: 0.9977 - precision: 0.4877 - recall: 0.9091 - dice_coef: 0.6303 - jacard_coef: 0.4620 - val_loss: 1.1903 - val_accuracy: 0.9982 - val_precision: 0.4316 - val_recall: 0.8184 - val_dice_coef: 0.5615 - val_jacard_coef: 0.3918\n","Epoch 19/40\n","512/512 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.9977 - precision: 0.4848 - recall: 0.8955 - dice_coef: 0.6250 - jacard_coef: 0.4562"]}],"source":["from keras.metrics import Precision, Recall\n","history=train(model,\n","          train_images=\"/content/drive/My Drive/mobilenet/dataset/images/\",\n","          train_annotations= \"/content/drive/My Drive/mobilenet/dataset/masks/\",\n","          input_height=1024,\n","          input_width=1024,\n","          n_classes=2,\n","          verify_dataset=True,\n","          checkpoints_path=\"/content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet\",\n","          epochs=40,\n","          batch_size=2,\n","          validate=True,\n","          val_images=\"/content/drive/My Drive/mobilenet/testdata/images\",\n","          val_annotations=\"/content/drive/My Drive/mobilenet/testdata/masks\",\n","          val_batch_size=2,\n","          auto_resume_checkpoint=False,\n","          load_weights=None,\n","          steps_per_epoch=512,\n","          val_steps_per_epoch=512,\n","          gen_use_multiprocessing=False,\n","          ignore_zero_class=False,\n","          optimizer_name='adam',\n","          do_augment=False,\n","          augmentation_name=\"aug_all\",\n","          callbacks=None,\n","          custom_augmentation=None,\n","          other_inputs_paths=None,\n","          preprocessing=None,\n","          read_image_type=1  \n","         )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmANhMehodln"},"outputs":[],"source":["model.save(\"/content/drive/My Drive/mobilenet/saved_model/mobilenet_unet.h5\")"]},{"cell_type":"markdown","metadata":{"id":"QIEB9yb9pkoy"},"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADwp2I_0bAJb"},"outputs":[],"source":["\n","def labelVisualize(num_class,color_dict,img):\n","    img = img[:,:,0] if len(img.shape) == 3 else img\n","    img_out = np.zeros(img.shape + (3,))\n","    for i in range(num_class):\n","        img_out[img == i,:] = color_dict[i]\n","        \n","    img_out= img_out/img_out.max()\n","    return img_out.astype(np.float16)\n"]},{"cell_type":"markdown","metadata":{"id":"AD0yGr2E7LNm"},"source":["## Accuracy plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7gN1Md1czGa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"3IqOd4Y07mE2"},"source":["## loss plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WERxqve87T7y"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RFROUOPt7pN9"},"source":["##Precision plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfbWOGoR7U3A"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['precision'])\n","plt.plot(history.history['val_precision'])\n","plt.title('model precision')\n","plt.ylabel('precision')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KGYYU33q7t2o"},"source":["## Recall plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Ja1tL9Z7Yvc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['recall'])\n","plt.plot(history.history['val_recall'])\n","plt.title('model recall')\n","plt.ylabel('recall')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DNLOXK7j7ylO"},"source":["##  Dice_coef plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyGxbgBm7aod"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['dice_coef'])\n","plt.plot(history.history['val_dice_coef'])\n","plt.title('model dice_coef')\n","plt.ylabel('dice_coef')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UYmPvlItCqJI"},"source":["##  Jacard_coef plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JC-lYlfT7diP"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['jacard_coef'])\n","plt.plot(history.history['val_jacard_coef'])\n","plt.title('model jacard_coef')\n","plt.ylabel('jacard_coef')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4LYo5v8Lc11q"},"source":["# Evaluating model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EmqChsP7czY"},"outputs":[],"source":["import glob\n","import random\n","import json\n","import os\n","import six\n","import cv2\n","import numpy as np\n","from tqdm import tqdm\n","from time import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOBrxC1f7d33"},"outputs":[],"source":["\n","def model_from_checkpoint_path(checkpoints_path):\n","    from keras_segmentation.models.all_models import model_from_name\n","    assert (os.path.isfile(checkpoints_path+\"_config.json\")\n","            ), \"Checkpoint not found.\"\n","    model_config = json.loads(\n","        open(checkpoints_path+\"_config.json\", \"r\").read())\n","    latest_weights = find_latest_checkpoint(checkpoints_path)\n","    print(latest_weights)\n","    assert (latest_weights is not None), \"Checkpoint not found.\"\n","    model = model_from_name[model_config['model_class']](\n","        model_config['n_classes'], input_height=model_config['input_height'],\n","        input_width=model_config['input_width'])\n","    print(\"loaded weights \", latest_weights)\n","    status = model.load_weights(latest_weights)\n","\n","    if status is not None:\n","        status.expect_partial()\n","    return model\n","\n","\n","def get_legends(class_names, colors=class_colors):\n","\n","    n_classes = len(class_names)\n","    legend = np.zeros(((len(class_names) * 25) + 25, 125, 3), dtype=\"uint8\") + 255\n","\n","    class_names_colors = enumerate(zip(class_names[:n_classes], colors[:n_classes]))\n","\n","    for (i, (class_name, color)) in class_names_colors:\n","        color = [int(c) for c in color]\n","        cv2.putText(\n","            legend,\n","            class_name,\n","            (5, (i * 25) + 17),\n","            cv2.FONT_HERSHEY_COMPLEX,\n","            0.5,\n","            (0, 0, 0),\n","            1,\n","        )\n","        cv2.rectangle(legend, (100, (i * 25)), (125, (i * 25) + 25), tuple(color), -1)\n","\n","    return legend\n","\n","\n","def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors):\n","    output_height = seg_arr.shape[0]\n","    output_width = seg_arr.shape[1]\n","\n","    seg_img = np.zeros((output_height, output_width, 3))\n","\n","    for c in range(n_classes):\n","        seg_arr_c = seg_arr[:, :] == c\n","        seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n","        seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n","        seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n","\n","    return seg_img\n","\n","def overlay_seg_image(inp_img, seg_img):\n","    orininal_h = inp_img.shape[0]\n","    orininal_w = inp_img.shape[1]\n","    seg_img = cv2.resize(seg_img, (orininal_w, orininal_h), interpolation=cv2.INTER_NEAREST)\n","\n","    fused_img = (inp_img/2 + seg_img/2).astype('uint8')\n","    return fused_img\n","\n","\n","def concat_lenends(seg_img, legend_img):\n","\n","    new_h = np.maximum(seg_img.shape[0], legend_img.shape[0])\n","    new_w = seg_img.shape[1] + legend_img.shape[1]\n","\n","    out_img = np.zeros((new_h, new_w, 3)).astype('uint8') + legend_img[0, 0, 0]\n","\n","    out_img[:legend_img.shape[0], :  legend_img.shape[1]] = np.copy(legend_img)\n","    out_img[:seg_img.shape[0], legend_img.shape[1]:] = np.copy(seg_img)\n","\n","    return \n","\n","def visualize_segmentation(seg_arr, inp_img=None, n_classes=None,\n","                           colors=class_colors, class_names=None,\n","                           overlay_img=False, show_legends=False,\n","                           prediction_width=None, prediction_height=None):\n","\n","    if n_classes is None:\n","        n_classes = np.max(seg_arr)\n","\n","    seg_img = get_colored_segmentation_image(seg_arr, n_classes, colors=colors)\n","\n","    if inp_img is not None:\n","        original_h = inp_img.shape[0]\n","        original_w = inp_img.shape[1]\n","        seg_img = cv2.resize(seg_img, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n","\n","    if (prediction_height is not None) and (prediction_width is not None):\n","        seg_img = cv2.resize(seg_img, (prediction_width, prediction_height), interpolation=cv2.INTER_NEAREST)\n","        if inp_img is not None:\n","            inp_img = cv2.resize(inp_img,\n","                                 (prediction_width, prediction_height))\n","\n","    if overlay_img:\n","        assert inp_img is not None\n","        seg_img = overlay_seg_image(inp_img, seg_img)\n","\n","    if show_legends:\n","        assert class_names is not None\n","        legend_img = get_legends(class_names, colors=colors)\n","\n","        seg_img = concat_lenends(seg_img, legend_img)\n","\n","    return seg_img"]},{"cell_type":"markdown","metadata":{"id":"1WJJH7TYGp94"},"source":["## Predict function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKGkgnGzGnAB"},"outputs":[],"source":["def predict(model=None, inp=None, out_fname=None,\n","            checkpoints_path=None, overlay_img=False,\n","            class_names=None, show_legends=False, colors=class_colors,\n","            prediction_width=None, prediction_height=None,\n","            read_image_type=1):\n","\n","    if model is None and (checkpoints_path is not None):\n","        model = model_from_checkpoint_path(checkpoints_path)\n","\n","    assert (inp is not None)\n","    assert ((type(inp) is np.ndarray) or isinstance(inp, six.string_types)),\\\n","        \"Input should be the CV image or the input file name\"\n","\n","    if isinstance(inp, six.string_types):\n","        inp = cv2.imread(inp, read_image_type)\n","\n","    assert (len(inp.shape) == 3 or len(inp.shape) == 1 or len(inp.shape) == 4), \"Image should be h,w,3 \"\n","\n","    output_width = model.output_width\n","    output_height = model.output_height\n","    input_width = model.input_width\n","    input_height = model.input_height\n","    n_classes = model.n_classes\n","\n","    x = get_image_array(inp, input_width, input_height,\n","                        ordering=IMAGE_ORDERING)\n","    pr = model.predict(np.array([x]))[0]\n","    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n","\n","    seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n","                                     colors=colors, overlay_img=overlay_img,\n","                                     show_legends=show_legends,\n","                                     class_names=class_names,\n","                                     prediction_width=prediction_width,\n","                                     prediction_height=prediction_height)\n","\n","    if out_fname is not None:\n","        cv2.imwrite(out_fname, seg_img)\n","\n","    return pr\n","    assert (len(inp.shape) == 3 or len(inp.shape) == 1 or len(inp.shape) == 4), \"Image should be h,w,3 \"\n","\n","    output_width = model.output_width\n","    output_height = model.output_height\n","    input_width = model.input_width\n","    input_height = model.input_height\n","    n_classes = model.n_classes\n","\n","    x = get_image_array(inp, input_width, input_height,\n","                        ordering=IMAGE_ORDERING)\n","    pr = model.predict(np.array([x]))[0]\n","    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n","\n","    seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n","                                     colors=colors, overlay_img=overlay_img,\n","                                     show_legends=show_legends,\n","                                     class_names=class_names,\n","                                     prediction_width=prediction_width,\n","                                     prediction_height=prediction_height)\n","\n","    if out_fname is not None:\n","        cv2.imwrite(out_fname, seg_img)\n","\n","    return pr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfxpuzSwiR-p"},"outputs":[],"source":["from  datetime import datetime\n","print(datetime.now())\n","predict_path=\"/content/drive/My Drive/mobilenet/outputs/\"\n","import os\n","file_names=os.listdir(predict_path)\n","predict_out=\"/content/drive/My Drive/mobilenet/testdata/images/\"\n","for i in range(len(file_names)):\n","  out =predict( model,\n","    inp=predict_path+file_names[i],\n","    out_fname=predict_out+file_names[i][:-4]+'.png'\n","    )\n","\n","print( datetime.now())"]},{"cell_type":"markdown","metadata":{"id":"_PlYGtAeGzsF"},"source":["## Evaluation function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhhqUT6KGzNx"},"outputs":[],"source":["def evaluate(model=None, inp_images=None, annotations=None,\n","             inp_images_dir=None, annotations_dir=None, checkpoints_path=None, read_image_type=1):\n","\n","    if model is None:\n","        assert (checkpoints_path is not None),\\\n","                \"Please provide the model or the checkpoints_path\"\n","        model = model_from_checkpoint_path(checkpoints_path)\n","        print(model)\n","    if inp_images is None:\n","        assert (inp_images_dir is not None),\\\n","                \"Please provide inp_images or inp_images_dir\"\n","        assert (annotations_dir is not None),\\\n","            \"Please provide inp_images or inp_images_dir\"\n","\n","        paths = get_pairs_from_paths(inp_images_dir, annotations_dir)\n","        paths = list(zip(*paths))\n","        inp_images = list(paths[0])\n","        annotations = list(paths[1])\n","\n","    assert type(inp_images) is list\n","    assert type(annotations) is list\n","    model.n_classes=2\n","    model.output_width=512\n","    model.output_height=512\n","    model.input_width=1024\n","    model.input_height=1024\n","    tp = np.zeros(model.n_classes)\n","    fp = np.zeros(model.n_classes)\n","    fn = np.zeros(model.n_classes)\n","    n_pixels = np.zeros(model.n_classes)\n","\n","    for inp, ann in tqdm(zip(inp_images, annotations)):\n","        pr = predict(model, inp, read_image_type=read_image_type)\n","        gt = get_segmentation_array(ann, model.n_classes,\n","                                    model.output_width, model.output_height,\n","                                    no_reshape=True, read_image_type=read_image_type)\n","        gt = gt.argmax(-1)\n","        pr = pr.flatten()\n","        gt = gt.flatten()\n","\n","        for cl_i in range(model.n_classes):\n","\n","            tp[cl_i] += np.sum((pr == cl_i) * (gt == cl_i))\n","            fp[cl_i] += np.sum((pr == cl_i) * ((gt != cl_i)))\n","            fn[cl_i] += np.sum((pr != cl_i) * ((gt == cl_i)))\n","            n_pixels[cl_i] += np.sum(gt == cl_i)\n","\n","    cl_wise_score = tp / (tp + fp + fn + 0.000000000001)\n","    n_pixels_norm = n_pixels / np.sum(n_pixels)\n","    frequency_weighted_IU = np.sum(cl_wise_score*n_pixels_norm)\n","    mean_IU = np.mean(cl_wise_score)\n","\n","    return {\n","        \"frequency_weighted_IU\": frequency_weighted_IU,\n","        \"mean_IU\": mean_IU,\n","        \"class_wise_IU\": cl_wise_score\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWaIEQWLx_aP"},"outputs":[],"source":["evaluate(model, inp_images_dir=\"/content/drive/My Drive/mobilenet/testdata/images/\", annotations_dir=\"/content/drive/My Drive/mobilenet/testdata/masks/\",\n","          checkpoints_path=\"/content/drive/My Drive/mobilenet/checkpoints/mobilenet_unet\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"mobilenet_segmentation_train.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}